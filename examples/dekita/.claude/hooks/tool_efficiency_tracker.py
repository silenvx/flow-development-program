#!/usr/bin/env python3
"""ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½è·¡ã—éåŠ¹ç‡ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã€‚

Why:
    åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¹°ã‚Šè¿”ã—èª­ã¿æ›¸ãã‚„ã€åŒã˜æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é‡è¤‡å®Ÿè¡Œã¯éåŠ¹ç‡ã€‚
    ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦è­¦å‘Šã™ã‚‹ã“ã¨ã§ã€ä½œæ¥­åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

What:
    - å…¨ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¾Œï¼ˆPostToolUseï¼‰ã«ç™ºç«
    - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å±¥æ­´ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§è¨˜éŒ²
    - éåŠ¹ç‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦è­¦å‘Šï¼ˆReadâ†’Editç¹°ã‚Šè¿”ã—ã€æ¤œç´¢é‡è¤‡ç­‰ï¼‰
    - æ¤œå‡ºçµæœã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ­ã‚°ã«è¨˜éŒ²

State:
    - reads/writes: /tmp/claude-hooks/tool-sequence.jsonï¼ˆå‘¼ã³å‡ºã—å±¥æ­´ï¼‰
    - writes: .claude/logs/metrics/tool-efficiency-metrics.log

Remarks:
    - éãƒ–ãƒ­ãƒƒã‚¯å‹ï¼ˆè­¦å‘Šã®ã¿ï¼‰
    - 10åˆ†ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ›´æ™‚ã«å±¥æ­´ãƒªã‚»ãƒƒãƒˆ

Changelog:
    - silenvx/dekita#xxx: ãƒ•ãƒƒã‚¯è¿½åŠ 
    - silenvx/dekita#1630: é«˜é »åº¦Reworkæ¤œå‡ºè¿½åŠ 
    - silenvx/dekita#2607: HookContextãƒ‘ã‚¿ãƒ¼ãƒ³ç§»è¡Œ
"""

import json
import sys
import tempfile
from datetime import UTC, datetime, timedelta
from pathlib import Path

from common import METRICS_LOG_DIR
from lib.execution import log_hook_execution
from lib.hook_input import get_tool_result
from lib.results import print_continue_and_log_skip
from lib.session import create_hook_context, get_session_id, parse_hook_input

# Time window for pattern detection (minutes)
PATTERN_WINDOW_MINUTES = 10

# Tracking file location (use TMPDIR for sandbox compatibility)
TRACKING_DIR = Path(tempfile.gettempdir()) / "claude-hooks"
TOOL_TRACKING_FILE = TRACKING_DIR / "tool-sequence.json"

# Persistent log for analysis
TOOL_EFFICIENCY_LOG = METRICS_LOG_DIR / "tool-efficiency-metrics.log"

# Maximum number of tool calls to keep in history
MAX_HISTORY_SIZE = 50

# Inefficient patterns to detect
# Format: (pattern_name, description, detector_function)


def load_tool_history() -> dict:
    """Load tool call history."""
    if TOOL_TRACKING_FILE.exists():
        try:
            return json.loads(TOOL_TRACKING_FILE.read_text())
        except Exception:
            pass  # Best effort - corrupted tracking data is ignored
    return {"calls": [], "session_id": None}


def save_tool_history(data: dict) -> None:
    """Save tool call history."""
    TRACKING_DIR.mkdir(parents=True, exist_ok=True)
    TOOL_TRACKING_FILE.write_text(json.dumps(data, indent=2))


def log_efficiency_event(pattern_name: str, description: str, details: dict) -> None:
    """Log efficiency event for later analysis."""
    try:
        METRICS_LOG_DIR.mkdir(parents=True, exist_ok=True)
        entry = {
            "timestamp": datetime.now(UTC).isoformat(),
            "session_id": get_session_id(),
            "type": "inefficiency_detected",
            "pattern_name": pattern_name,
            "description": description,
            "details": details,
        }
        with open(TOOL_EFFICIENCY_LOG, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except OSError:
        pass  # ãƒ­ã‚°æ›¸ãè¾¼ã¿å¤±æ•—ã¯ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ç„¡è¦–ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å¿…é ˆã§ã¯ãªã„ï¼‰


def extract_target(tool_name: str, tool_input: dict) -> str | None:
    """Extract the target (file/pattern) from tool input."""
    if tool_name in ("Read", "Edit", "Write"):
        return tool_input.get("file_path")
    elif tool_name == "Glob":
        return tool_input.get("pattern")
    elif tool_name == "Grep":
        return tool_input.get("pattern")
    elif tool_name == "Bash":
        return tool_input.get("command", "")[:100]  # First 100 chars
    return None


def detect_read_edit_loop(calls: list[dict]) -> dict | None:
    """Detect Read â†’ Edit â†’ Read â†’ Edit pattern on same file.

    This pattern suggests the edit wasn't complete on first try.
    """
    # Need at least 4 calls for this pattern
    if len(calls) < 4:
        return None

    # Look at last 6 calls
    recent = calls[-6:]

    # Find Read-Edit pairs on the same file
    file_edit_counts: dict[str, int] = {}
    for i, call in enumerate(recent):
        if call["tool"] == "Edit" and call.get("target"):
            target = call["target"]
            # Check if preceded by Read on same file
            for j in range(max(0, i - 2), i):
                if recent[j]["tool"] == "Read" and recent[j].get("target") == target:
                    file_edit_counts[target] = file_edit_counts.get(target, 0) + 1
                    break

    # Report if any file had 2+ Read-Edit cycles
    for file_path, count in file_edit_counts.items():
        if count >= 2:
            return {
                "pattern": "read_edit_loop",
                "file": file_path,
                "cycles": count,
            }

    return None


def detect_repeated_search(calls: list[dict]) -> dict | None:
    """Detect repeated Glob/Grep with similar patterns.

    This suggests the search strategy could be improved.
    """
    # Look at last 10 calls
    recent = calls[-10:]

    search_patterns: dict[str, int] = {}
    for call in recent:
        if call["tool"] in ("Glob", "Grep") and call.get("target"):
            # Normalize pattern for comparison
            pattern = call["target"].lower()
            search_patterns[pattern] = search_patterns.get(pattern, 0) + 1

    # Report if any pattern was searched 3+ times
    for pattern, count in search_patterns.items():
        if count >= 3:
            return {
                "pattern": "repeated_search",
                "search_pattern": pattern,
                "count": count,
            }

    return None


def detect_bash_retry(calls: list[dict]) -> dict | None:
    """Detect repeated Bash command failures.

    This suggests the command or approach needs reconsideration.
    """
    # Look at last 5 Bash calls
    bash_calls = [c for c in calls[-10:] if c["tool"] == "Bash"]

    if len(bash_calls) < 3:
        return None

    # Count failures
    failures = [c for c in bash_calls if not c.get("success", True)]
    if len(failures) >= 3:
        return {
            "pattern": "bash_retry",
            "failure_count": len(failures),
            "commands": [c.get("target", "")[:50] for c in failures[-3:]],
        }

    return None


def detect_high_frequency_rework(calls: list[dict], now: datetime) -> dict | None:
    """Detect high-frequency rework on the same file.

    Issue #1630: 5åˆ†é–“ã§3å›ä»¥ä¸Šã®åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ã‚’æ¤œå‡ºã€‚

    å‘¼ã³å‡ºã—å…ƒã® main() ã§ã¯ã€å±¥æ­´å…¨ä½“ã‹ã‚‰ç›´è¿‘ PATTERN_WINDOW_MINUTES åˆ†ã®
    ã‚³ãƒ¼ãƒ«ã ã‘ã‚’æŠ½å‡ºã—ã¦ã‹ã‚‰ã“ã®é–¢æ•°ã« calls ã‚’æ¸¡ã—ã¦ã„ã‚‹ã€‚
    ã“ã®é–¢æ•°ã§ã¯ã•ã‚‰ã«ã€ãã®ä¸­ã‹ã‚‰ç›´è¿‘ 5 åˆ†é–“ã®ã‚³ãƒ¼ãƒ«ã ã‘ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã‚‹ãŸã‚ã€
    ã€Œã‚°ãƒ­ãƒ¼ãƒãƒ«ãª 10 åˆ†ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«å¯¾ã™ã‚‹ã€ã‚ˆã‚Šå³ã—ã‚ã® 5 åˆ†ãƒ­ãƒ¼ã‚«ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã€
    ã¨ã„ã†äºŒé‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ãªã£ã¦ã„ã‚‹ã€‚

    Args:
        calls (list[dict]): ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å±¥æ­´
        now (datetime): ç¾åœ¨æ™‚åˆ»ï¼ˆmain()ã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ä¸€è²«æ€§ã®ãŸã‚ï¼‰

    This suggests the changes weren't well-planned.
    """
    # ç›´è¿‘ 5 åˆ†ã®ã‚³ãƒ¼ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ï¼ˆå‘¼ã³å‡ºã—å…ƒã® 10 åˆ†ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«å¯¾ã™ã‚‹è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
    window_5min = now - timedelta(minutes=5)
    recent_5min = [c for c in calls if datetime.fromisoformat(c["timestamp"]) > window_5min]

    # Filter to Edit calls with targets
    edit_calls = [c for c in recent_5min if c["tool"] == "Edit" and c.get("target")]

    if len(edit_calls) < 3:
        return None

    # Count edits per file
    file_edit_counts: dict[str, int] = {}
    for call in edit_calls:
        target = call["target"]
        file_edit_counts[target] = file_edit_counts.get(target, 0) + 1

    # Find files with 3+ edits
    for file_path, count in file_edit_counts.items():
        if count >= 3:
            return {
                "pattern": "high_frequency_rework",
                "file": file_path,
                "edit_count": count,
            }

    return None


def main():
    """PostToolUse hook for all tools.

    Tracks tool calls and detects inefficient patterns.
    """
    result = {"continue": True}

    try:
        input_data = parse_hook_input()
        # Issue #2607: Create context for session_id logging
        ctx = create_hook_context(input_data)
        tool_name = input_data.get("tool_name", "")
        tool_input = input_data.get("tool_input", {})
        tool_result = get_tool_result(input_data) or {}

        # Skip if no tool name
        if not tool_name:
            print_continue_and_log_skip("tool-efficiency-tracker", "no tool name", ctx=ctx)
            return

        now = datetime.now(UTC)
        current_session = get_session_id()

        # Load history
        history = load_tool_history()

        # Reset if session changed
        if history.get("session_id") != current_session:
            history = {"calls": [], "session_id": current_session}

        # Determine success (for Bash, check exit code)
        success = True
        if tool_name == "Bash":
            exit_code = tool_result.get("exit_code", 0)
            success = exit_code == 0

        # Create call record
        call_record = {
            "timestamp": now.isoformat(),
            "tool": tool_name,
            "target": extract_target(tool_name, tool_input),
            "success": success,
        }

        # Add to history
        history["calls"].append(call_record)

        # Trim history to max size
        if len(history["calls"]) > MAX_HISTORY_SIZE:
            history["calls"] = history["calls"][-MAX_HISTORY_SIZE:]

        # Save updated history
        save_tool_history(history)

        # Filter to recent calls within window
        window_start = now - timedelta(minutes=PATTERN_WINDOW_MINUTES)
        recent_calls = [
            c for c in history["calls"] if datetime.fromisoformat(c["timestamp"]) > window_start
        ]

        # Detect patterns
        patterns_detected = []

        read_edit = detect_read_edit_loop(recent_calls)
        if read_edit:
            patterns_detected.append(read_edit)

        repeated = detect_repeated_search(recent_calls)
        if repeated:
            patterns_detected.append(repeated)

        bash_retry = detect_bash_retry(recent_calls)
        if bash_retry:
            patterns_detected.append(bash_retry)

        # Issue #1630: Add high-frequency rework detection
        rework = detect_high_frequency_rework(recent_calls, now)
        if rework:
            patterns_detected.append(rework)

        # Log and report patterns
        if patterns_detected:
            for pattern in patterns_detected:
                pattern_name = pattern["pattern"]
                if pattern_name == "read_edit_loop":
                    log_efficiency_event(
                        pattern_name,
                        f"ãƒ•ã‚¡ã‚¤ãƒ« {pattern['file']} ã§ Readâ†’Edit ãŒ {pattern['cycles']} å›ç¹°ã‚Šè¿”ã—",
                        pattern,
                    )
                elif pattern_name == "repeated_search":
                    log_efficiency_event(
                        pattern_name,
                        f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern['search_pattern']}' ã‚’ {pattern['count']} å›æ¤œç´¢",
                        pattern,
                    )
                elif pattern_name == "bash_retry":
                    log_efficiency_event(
                        pattern_name,
                        f"Bashã‚³ãƒãƒ³ãƒ‰ãŒ {pattern['failure_count']} å›å¤±æ•—",
                        pattern,
                    )
                elif pattern_name == "high_frequency_rework":
                    log_efficiency_event(
                        pattern_name,
                        f"ãƒ•ã‚¡ã‚¤ãƒ« {pattern['file']} ã‚’ {pattern['edit_count']} å›ç·¨é›†ï¼ˆé«˜é »åº¦Reworkï¼‰",
                        pattern,
                    )

            # Show message for first pattern only
            first = patterns_detected[0]
            if first["pattern"] == "read_edit_loop":
                result["systemMessage"] = (
                    f"ğŸ“Š åŠ¹ç‡æ€§: {Path(first['file']).name} ã® "
                    f"Readâ†’Edit ãŒ {first['cycles']} å›ç¹°ã‚Šè¿”ã—ã€‚\n"
                    "äº‹å‰èª¿æŸ»ã§ç·¨é›†å†…å®¹ã‚’ç¢ºå®šã•ã›ã‚‹ã¨åŠ¹ç‡çš„ã§ã™ã€‚"
                )
            elif first["pattern"] == "repeated_search":
                result["systemMessage"] = (
                    f"ğŸ“Š åŠ¹ç‡æ€§: åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ {first['count']} å›æ¤œç´¢ã€‚\n"
                    "æ¤œç´¢çµæœã‚’æ´»ç”¨ã™ã‚‹ã‹ã€Task toolã§æ¢ç´¢ã™ã‚‹ã¨åŠ¹ç‡çš„ã§ã™ã€‚"
                )
            elif first["pattern"] == "bash_retry":
                result["systemMessage"] = (
                    f"ğŸ“Š åŠ¹ç‡æ€§: Bashã‚³ãƒãƒ³ãƒ‰ãŒ {first['failure_count']} å›å¤±æ•—ã€‚\n"
                    "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
                )
            elif first["pattern"] == "high_frequency_rework":
                result["systemMessage"] = (
                    f"ğŸ“Š åŠ¹ç‡æ€§: {Path(first['file']).name} ã‚’ "
                    f"{first['edit_count']} å›ç·¨é›†ï¼ˆé«˜é »åº¦Reworkï¼‰ã€‚\n"
                    "ç·¨é›†å‰ã«å¤‰æ›´å†…å®¹ã‚’ç¢ºå®šã•ã›ã‚‹ã¨åŠ¹ç‡çš„ã§ã™ã€‚"
                )

            # Issue #1630: å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åŒ– - stderrã«ã‚‚å‡ºåŠ›
            if "systemMessage" in result:
                stderr_msg = f"[tool-efficiency-tracker] {result['systemMessage']}"
                print(stderr_msg, file=sys.stderr)

    except Exception:
        # ãƒ•ãƒƒã‚¯å®Ÿè¡Œã®å¤±æ•—ã§Claude Codeã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„
        pass

    log_hook_execution(
        "tool-efficiency-tracker",
        "approve",
        details={"type": "tool_tracked"},
    )
    print(json.dumps(result))


if __name__ == "__main__":
    main()
